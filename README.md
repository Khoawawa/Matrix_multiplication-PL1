# Parallel Matrix Multiplication: Naive & Strassen Algorithms

## Overview

This repository implements **matrix multiplication** using both the **Naive algorithm** and **Strassenâ€™s algorithm**, with a strong focus on **parallel and high-performance computing techniques**. The project explores and compares different parallelization models, including:

- **OpenMP (shared-memory parallelism)**
- **MPI (distributed-memory parallelism)**
- **Hybrid OpenMP + MPI**
- **GPU acceleration using CUDA**

The goal is to analyze performance, scalability, and efficiency across multiple computing architectures.

---

## Features

- Implementation of **Naive Matrix Multiplication**
- Implementation of **Strassen Matrix Multiplication**
- Parallel execution using **OpenMP**
- Distributed execution using **MPI** for cluster-based systems
- **Hybrid OpenMP + MPI** model for cluster-based systems
- **CUDA-based GPU acceleration** for large-scale matrices
- Performance benchmarking and comparison

---

## Algorithms

### Naive Matrix Multiplication

The naive approach computes matrix multiplication with three nested loops:

- Time complexity: **O(nÂ³)**
- Simple and easy to parallelize
- Performs well for small to medium matrix sizes

### Strassenâ€™s Matrix Multiplication

Strassenâ€™s algorithm reduces the number of multiplications by recursively dividing matrices:

- Time complexity: **O(n^logâ‚‚7) â‰ˆ O(nÂ².81)**
- More efficient for large matrices
- Higher overhead and memory usage
- Requires careful optimization in parallel environments

---

## Project Structure

```text
Matrix_multiplication-PL1/
â”œâ”€â”€ include/         
â”‚   â”œâ”€â”€ Matrix.tpp
â”‚   â”œâ”€â”€ Matrix.h
â”‚   â”œâ”€â”€ MatrixView.tpp
â”‚   â”œâ”€â”€ HybridMatrix.h
â”‚   â”œâ”€â”€ HybridMatrix.tpp
â”‚   â””â”€â”€ strassen.h
â”œâ”€â”€ sequential.cpp
â”œâ”€â”€ omp.cpp
â”œâ”€â”€ MPIStrassen.tpp
â”œâ”€â”€ MPIStrassen.h
â”œâ”€â”€ main_MPI.cpp
â”œâ”€â”€ main_hybrid.cpp
â”œâ”€â”€ gpu.cu
â””â”€â”€ README.md
```

---

##  Compilation and Execution

### Sequential

```bash
g++ -fopenmp sequential.cpp -Iinclude -o seq
./seq
```

### OpenMP

```bash
g++ -fopenmp omp.cpp -Iinclude -o omp
OMP_NUM_THREADS=16 ./omp
```

### MPI (Run on the provided cluster)

```bash
mpicxx -fopenmp -Iinclude main_MPI.cpp -o main_MPI
mpirun -np 24 --hostfile host.txt ./main_MPI
```

### Hybrid OpenMP + MPI (Run on the provided cluster)

```bash
mpicxx -fopenmp -Iinclude main_hybrid.cpp -o main_hybrid
OMP_NUM_THREADS=8 mpirun -np 24 --hostfile host.txt ./main_hybrid
```

### CUDA

```bash
nvcc -O3 -arch=sm_70 gpu.cu -o gpu
./gpu
```

---

## ðŸ“Š Performance Evaluation

- Execution time measured for different matrix sizes
- Comparison between Naive and Strassen algorithms
- Speedup analysis across OpenMP, MPI, Hybrid, and CUDA implementations
- Evaluation of scalability and communication overhead

---


